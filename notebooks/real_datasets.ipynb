{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook\n",
    "builds a graph-based embedding for a small number of random handwritten digits with multidimensional scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: run this before import to recompile c++ ops\n",
    "```\n",
    "!rm -r ../lib/cpp/temp/\n",
    "!rm -r ../lib/cpp/build/\n",
    "!rm -r ../lib/cpp/_bindings.so\n",
    "!rm -r ../lib/cpp/bindings.py\n",
    "!rm -r ../lib/cpp/lib_wrap.c\n",
    "```\n",
    "\n",
    "\n",
    "##### Get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gc\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import lib # builds c++ binaries with swig\n",
    "from lib.utils.distance_helper import compute_original_pairwise_distance, compute_pca_pairwise_distance, mds_pairwise_distance\n",
    "from lib import data_loader as data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose 1 of the 4 datasets to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'fashion_mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'fiw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'newsgroup'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'fashion_mnist':\n",
    "    X, y = data_loader.get_fashion_mnist(10000)\n",
    "    batch_size = 256\n",
    "elif dataset == 'cifar':\n",
    "    X, y = data_loader.get_cifar10(10000)\n",
    "    batch_size = 256\n",
    "elif dataset == 'fiw':\n",
    "    X, y = data_loader.get_faces_in_wild()\n",
    "    batch_size = 256\n",
    "elif dataset == 'newsgroup':\n",
    "    X, y = data_loader.get_newsgroup_vectors()\n",
    "    batch_size = 256\n",
    "else:\n",
    "    raise Exception(f\"Unspecified dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute PCA and MDS compression MSE (pre-computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.load(f'./data/{dataset}_dist.npy')\n",
    "dist_pca = np.load(f'./data/{dataset}_pca.npy')\n",
    "dist_mds = np.load(f'./data/{dataset}_mds.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Else compute them using the cell below\n",
    "#### Will take a few hours and huge CPU & Memory resources, even with our optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distances = compute_original_pairwise_distance(X, simple=False, num_samples=len(X), temp_filename=f'{dataset}_dist')\n",
    "# dist_pca = compute_pca_pairwise_distance(X, simple=False, num_samples=len(X), temp_filename=f'{dataset}_pca')\n",
    "# dist_mds = mds_pairwise_distance(X)\n",
    "# np.save(f'./data/{dataset}_dist.npy', distances)\n",
    "# np.save(f'./data/{dataset}_pca.npy', dist_pca)\n",
    "# np.save(f'./data/{dataset}_mds.npy', dist_mds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build initial graph\n",
    "\n",
    "We initialize prodige with a full graph initialized with distances between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = lib.initalize_prodige(X, knn_edges=64, random_edges=32,verbose=True)\n",
    "\n",
    "prune_threshold = 0.5  # increase up to 0.9 for faster convergence\n",
    "loss_history, reg_history = [], []\n",
    "opt = None\n",
    "total_edges = emb.num_edges\n",
    "num_edges_req = len(X) * 2 * 1.1  # *1.1 as buffer\n",
    "stage, last_updated = 0, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loop\n",
    "\n",
    "Here we minimize the MDS loss function\n",
    "$$L = 1/N \\sum_{i, j} (d_{orig}(x_i, x_j) - d_G(v_i, v_j))^2$$\n",
    "\n",
    "* $d_{orig}(x_i, x_j)$ is the original distance between two vectors in $X$\n",
    "* $d_G(v_i, v_j)$ is the learned graph distance between corresponding vertices in graph $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage, emb, opt = lib.update_learning_rate(stage, len(loss_history), emb, prune_threshold=prune_threshold)\n",
    "print(\"Stage:\", stage)\n",
    "for i in tqdm(range(len(loss_history), 10000)):\n",
    "    source = torch.randint(0, len(X), [batch_size])\n",
    "    target = torch.randint(0, len(X), [batch_size])\n",
    "\n",
    "    pred = emb(source, target)\n",
    "    distances_ref = torch.as_tensor(distances[source, target], dtype=torch.float32)\n",
    "    \n",
    "    reconstruction_mse = F.mse_loss(pred['target_distances'], distances_ref)\n",
    "    regularizer = emb.compute_l0_prior_penalty(4096)\n",
    "    lambd = min(1, len(loss_history) / 10000.) * (emb.num_edges / total_edges) * 10.0\n",
    "    # Equation 2 + log deriative trick\n",
    "    loss = reconstruction_mse - pred['logp_target_paths'].mean() + lambd * regularizer\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_history.append(reconstruction_mse.item())\n",
    "    reg_history.append(regularizer.item())\n",
    "    \n",
    "    # early stopping       \n",
    "    edges_kept = np.sum(lib.check_numpy(emb.edge_adjacency_logits >= 0).astype('int64'))\n",
    "    if edges_kept <= num_edges_req:\n",
    "        print('Early stopping at epoch:', i)\n",
    "        break\n",
    "\n",
    "    # dynamic updating of LR/pruning  \n",
    "    if len(reg_history) > 100 and i > last_updated:\n",
    "        limit = round(reg_history[-30], 3)\n",
    "        if stage <= 3:\n",
    "            if all(round(i, 3) >= limit for i in reg_history[-30:]):\n",
    "                stage, emb, opt = lib.update_learning_rate(stage, len(loss_history), emb, prune_threshold=prune_threshold)\n",
    "                last_updated = i + 50\n",
    "        else:\n",
    "            if all(round(i, 3) >= limit for i in reg_history[-30:]):\n",
    "                stage, emb, opt = lib.update_learning_rate(stage, len(loss_history), emb, \n",
    "                                                           prune_threshold=prune_threshold, decrease_lr=False)\n",
    "                last_updated = i + 500\n",
    "\n",
    "    if len(loss_history) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        print(\"Stage:\", stage)\n",
    "        plt.figure(figsize=[15, 4])\n",
    "        plt.subplot(1, 2, 1);\n",
    "        plt.title('mse = %.20f' % loss_history[-1]); plt.grid()\n",
    "        plt.plot(loss_history)\n",
    "        plt.subplot(1, 2, 2);\n",
    "        plt.title('regularizer = %0.5f' % reg_history[-1]); plt.grid()\n",
    "        plt.plot(reg_history)\n",
    "        plt.show()\n",
    "        print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_prodige = emb.compute_pairwise_distances()\n",
    "emb.report_model_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA:\\t %.5f\" % np.mean(np.square(distances - dist_pca)))\n",
    "print(\"MDS:\\t %.5f\" % np.mean(np.square(distances - dist_mds)))\n",
    "print(\"PRODIGE: %.5f\" % np.mean(np.square(distances - dist_prodige)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate PRODIGE as a NetworkX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = lib.generate_networkx_graph(emb, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(f'{dataset}_graph.html')\n",
    "p = lib.draw_networkx_graph(G, dataset, weighted=True)\n",
    "save(p, f'{dataset}_graph.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
