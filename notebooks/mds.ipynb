{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This notebook__ compares PCA, MDS and Probabilistic Differentiable Graph Embeddings for the task of isometric compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import lib\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import trange\n",
    "from IPython.display import clear_output\n",
    "from gensim.downloader import load, info\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = load('glove-wiki-gigaword-300')\n",
    "words = sorted(glove.vocab.keys(), key=lambda w: glove.vocab[w].index)[:10000] # 12mb\n",
    "X = glove[words].astype('float32')\n",
    "X = X / np.square(X).sum(-1, keepdims=True) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4) # 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = lfw_people.data # shape: (1288, 1850)  i.e. 1288 samples, flattened array of 1850 length\n",
    "y = lfw_people.target  # 7 labels\n",
    "# lfw_people.images.shape  # 50 * 37 = 1850\n",
    "# lfw_people.target_names  # 7 people\n",
    "# ['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush', 'Gerhard Schroeder' 'Hugo Chavez' 'Tony Blair']\n",
    "# lfw_people.DESCR\n",
    "# 9.5mb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=10, resize=0.4)\n",
    "X = lfw_people.data # shape: (3199, 1850)  i.e. 3199 samples, flattened array of 1850 length\n",
    "y = lfw_people.target  # 92 labels\n",
    "# lfw_people.target_names  # 92 people\n",
    "# 23mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "news_vectors = fetch_20newsgroups_vectorized()  # type: sklearn.utils.Bunch\n",
    "X = news_vectors.data.toarray() # shape: (11314, 130107)  i.e. 11314 samples, max embedding length 130107\n",
    "y = news_vectors.target  # 20 labels\n",
    "# news_vectors.target_names  # 20 categories\n",
    "# news_vectors.DESCR\n",
    "# 11.7gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../lib/task/compression/__init__.py:49: UserWarning: faiss not found, using slow knn instead\n",
      "  warn(\"faiss not found, using slow knn instead\")\n"
     ]
    }
   ],
   "source": [
    "from lib.task.compression import make_graph_from_vectors\n",
    "emb = make_graph_from_vectors(\n",
    "        X, knn_edges=64, random_edges=32, squared=False,\n",
    "        max_length=10, n_jobs=-1, soft=True, k_nearest=0, directed=False\n",
    ")\n",
    "\n",
    "loss_history, reg_history = [], []\n",
    "batch_size = 256\n",
    "opt = None\n",
    "total_edges = emb.num_edges\n",
    "stage = 0\n",
    "\n",
    "def update_learning_rate():\n",
    "    t = len(loss_history)\n",
    "    global opt, stage, emb, batch_size\n",
    "    \n",
    "    if stage == 0:\n",
    "        opt = torch.optim.SparseAdam(emb.parameters(), lr=0.1)\n",
    "        stage += 1\n",
    "        \n",
    "    if stage == 1 and t >= 3000:\n",
    "        emb = emb.pruned(threshold=0.5)\n",
    "        opt = torch.optim.SparseAdam(emb.parameters(), lr=0.05)\n",
    "        stage += 1\n",
    "    \n",
    "    if stage == 2 and t >= 10000:\n",
    "        emb = emb.pruned(threshold=0.5)\n",
    "        opt = torch.optim.SparseAdam(emb.parameters(), lr=0.01)\n",
    "        stage += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [10:59<00:00, 16.49s/it]\n"
     ]
    }
   ],
   "source": [
    "# pre-compute reference distances\n",
    "distances = np.concatenate([\n",
    "    np.square(X[None, :, :] - X[batch_start: batch_start + batch_size, None, :]).sum(-1) ** 0.5\n",
    "    for batch_start in trange(0, len(X), batch_size)\n",
    "])\n",
    "# ^-- replacing cosine with squared l2 distance because\n",
    "# |x - y|_2^2 = |x|_2^2 + |y|_2^2- 2 * <x, y> and |x| = |y| = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab78cf167fb24ecfa14b2706a57573b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-24b9d1058d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdistances_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/prodige/lib/graph_embedding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, from_ix, to_ix, **parameters)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0medge_weight_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mfrom_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_ix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/prodige/lib/cpp/__init__.py\u001b[0m in \u001b[0;36mbatch_dijkstra\u001b[0;34m(slices, sliced_edges, sliced_adjacency_logits, sliced_weight_logits, initial_vertices, target_vertices, k_nearest, max_length, max_length_nearest, max_steps, deterministic, presample_edges, soft, n_jobs, validate)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0minitial_vertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vertices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mtarget_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnearest_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_i in tqdm(range(len(loss_history), 100000)):\n",
    "    # print(end='.')\n",
    "    update_learning_rate()\n",
    "    ii = torch.randint(0, len(X), [batch_size])\n",
    "    jj = torch.randint(0, len(X), [batch_size])\n",
    "    \n",
    "    pred = emb(ii, jj)\n",
    "    distances_ref = torch.as_tensor(distances[ii, jj], dtype=torch.float32)\n",
    "    \n",
    "    reconstruction_mse = F.mse_loss(pred['target_distances'], distances_ref)\n",
    "    regularizer = emb.compute_l0_prior_penalty(batch_size=4096)\n",
    "    \n",
    "    lambd = min(1, len(loss_history) / 10000.) * (emb.num_edges / total_edges) * 10.0\n",
    "    loss = reconstruction_mse - pred['logp_target_paths'].mean() + lambd * regularizer\n",
    "            \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_history.append(reconstruction_mse.item())\n",
    "    reg_history.append(regularizer.item())\n",
    "    \n",
    "    #if len(loss_history) % 50 == 0:\n",
    "clear_output(True)\n",
    "plt.figure(figsize=[15, 4])\n",
    "plt.subplot(1, 3, 1);\n",
    "plt.title('reconstruction mse, mean = %0.5f' % np.mean(loss_history[-100:])); plt.grid()\n",
    "plt.plot(loss_history)\n",
    "\n",
    "plt.subplot(1, 3, 2);\n",
    "plt.title('regularizer, mean = %0.5f' % np.mean(reg_history[-100:])); plt.grid()\n",
    "plt.plot(reg_history)\n",
    "\n",
    "plt.subplot(1, 3, 3);\n",
    "probs = torch.sigmoid(emb.edge_adjacency_logits).data.numpy().ravel()\n",
    "plt.title('P(edge), nonzero rate = %.5f' % (np.sum(probs > 0.5) / total_edges))\n",
    "plt.grid();\n",
    "plt.hist(probs)\n",
    "plt.show()\n",
    "\n",
    "# batch/s rate will increase at 5k and 10k steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"params per vertex = %.4f\" % (emb.report_model_size()['num_parameters'] / len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_ours = emb.compute_pairwise_distances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines:\n",
    "\n",
    "We train two other common compression methods as our baselines:\n",
    "* __PCA:__ Principial Component Analysis learns to project data onto lower dimensional space in a way that captures as much variance as possible. This method is considered a __weak__ baseline as it does not minimize the target metric.\n",
    "* __MDS:__ Multidimensional Scaling solves the same optimization problem as our method, but in a vector space. We expect this method to outperform PCA given the same number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4).fit(X)\n",
    "X_pca = pca.inverse_transform(pca.transform(X))\n",
    "distances_pca = np.concatenate([\n",
    "    np.square(X_pca[None, :, :] - X_pca[batch_start: batch_start + batch_size, None, :]).sum(-1) ** 0.5\n",
    "    for batch_start in range(0, len(X_pca), batch_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components=4, random_state=42, n_jobs=-1, dissimilarity='euclidean')\n",
    "X_mds = mds.fit_transform(X)\n",
    "distances_mds = np.square(X_mds[None, :, :] - X_mds[:, None, :]).sum(-1) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA:\\t %.5f\" % np.mean(np.square(distances - distances_pca)))\n",
    "print(\"MDS:\\t %.5f\" % np.mean(np.square(distances - distances_mds)))\n",
    "print(\"PRODIGE: %.5f\" % np.mean(np.square(distances - distances_ours)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
