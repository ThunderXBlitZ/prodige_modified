{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This notebook__ compares PCA, MDS and Probabilistic Differentiable Graph Embeddings for the task of isometric compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os, sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import lib\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import trange\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 13002/55187 [00:02<00:05, 7134.24it/s]"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"./Pinterest\"):\n",
    "    !wget https://www.dropbox.com/s/gtlafw4kp77d7nl/pinterest.tar.gz?dl=1 -O pinterest.tar.gz\n",
    "    !tar -xvzf pinterest.tar.gz\n",
    "    !rm pinterest.tar.gz\n",
    "\n",
    "from lib.task.colaborative.pinterest import Dataset\n",
    "data = Dataset(\"./Pinterest/pinterest-20\")\n",
    "matrix = data.trainMatrix.tocsr().sorted_indices()\n",
    "\n",
    "positives = {i: matrix.getrow(i).nonzero()[1] for i in trange(matrix.shape[0])}\n",
    "num_users, num_items = matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.task.colaborative import make_graph_colaborative\n",
    "emb = make_graph_colaborative(\n",
    "       matrix.toarray(), knn_edges=4, score_to_distance=lambda x: 1. / x, verbose=True,\n",
    "       max_length=10, n_jobs=-1, soft=True, k_nearest=0, directed=False,\n",
    ")\n",
    "\n",
    "def user_to_vertex(ix):\n",
    "    return torch.as_tensor(ix) + num_items\n",
    "\n",
    "def item_to_vertex(ix):\n",
    "    return torch.as_tensor(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history, reg_history, recall_history = [], [], []\n",
    "\n",
    "total_edges = emb.num_edges\n",
    "stage = 0\n",
    "num_positives = 10\n",
    "k_nearest = 256\n",
    "num_negatives = 100\n",
    "skip_negatives = 10\n",
    "batch_size = 64\n",
    "opt = None\n",
    "\n",
    "def update_learning_rate():\n",
    "    t = len(loss_history)\n",
    "    global opt, stage, emb, batch_size\n",
    "    \n",
    "    if stage == 0:\n",
    "        opt = torch.optim.SparseAdam(emb.parameters(), lr=0.1)\n",
    "        stage += 1\n",
    "        \n",
    "    if stage == 1 and t >= 5000:\n",
    "        emb = emb.pruned(threshold=0.5)\n",
    "        opt = torch.optim.SparseAdam(emb.parameters(), lr=0.05)\n",
    "        stage += 1\n",
    "    \n",
    "    if stage == 2 and t >= 10000:\n",
    "        emb = emb.pruned(threshold=0.1)\n",
    "        opt = torch.optim.SparseAdam(emb.parameters(), lr=0.01)\n",
    "        stage += 1\n",
    "\n",
    "\n",
    "def eval_recall(batch_size=batch_size, k=10):\n",
    "    user_ix, pos_items = map(torch.tensor, zip(*data.testRatings))\n",
    "    assert torch.all(user_ix == torch.arange(num_users)).item()\n",
    "    neg_items = torch.as_tensor(data.testNegatives)\n",
    "\n",
    "    ix = torch.randint(num_users, size=[batch_size])\n",
    "    user_ix, pos_items, neg_items = user_ix[ix], pos_items[ix], neg_items[ix]\n",
    "    pos_and_neg = torch.cat([pos_items[:, None], neg_items], dim=1)\n",
    "    pred_pos_and_neg = emb(user_to_vertex(user_ix), item_to_vertex(pos_and_neg), deterministic=True)\n",
    "    ordered = pred_pos_and_neg['target_distances'].data.numpy().argsort(-1)\n",
    "    positive_indices = np.array([list(row).index(0) for row in ordered])\n",
    "    return np.mean(positive_indices < k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_i in range(len(loss_history), 100000):\n",
    "    print(end='.')\n",
    "    update_learning_rate()\n",
    "    users = torch.randint(0, num_users, (batch_size,))\n",
    "    items_positive = torch.as_tensor(\n",
    "        [np.random.choice(positives[i], replace=num_positives > len(positives[i]), size=num_positives)\n",
    "         for i in lib.check_numpy(users)], dtype=torch.int32)\n",
    "    \n",
    "    items_negative = torch.randint(0, num_items, size=(batch_size, num_negatives), dtype=torch.int32)\n",
    "    items_posneg = torch.cat([items_positive, items_negative], dim=-1)\n",
    "    \n",
    "    pred = emb(user_to_vertex(users), item_to_vertex(items_posneg), max_steps=10 ** 5)\n",
    "    distances_positive = pred['target_distances'][:, :num_positives]\n",
    "    distances_negative = pred['target_distances'][:, num_positives:]\n",
    "    log_numerator = -distances_positive\n",
    "    logaddexp_negatives = torch.logsumexp(-distances_negative, dim=-1)\n",
    "    log_denominator = torch.log(torch.exp(log_numerator) + \\\n",
    "                                torch.exp(logaddexp_negatives)[:, None])\n",
    "    loss = torch.mean(-log_numerator + log_denominator)\n",
    "    \n",
    "    \n",
    "    regularizer = emb.compute_l0_prior_penalty(batch_size=4096)\n",
    "    lambd = min(1, len(loss_history) / 10000.) * (emb.num_edges / total_edges) * 20.0\n",
    "    obj = loss - pred['logp_target_paths'][:, :num_positives].mean() + lambd * regularizer\n",
    "            \n",
    "    opt.zero_grad()\n",
    "    obj.backward()\n",
    "    opt.step()\n",
    "    loss_history.append(loss.item())\n",
    "    reg_history.append(regularizer.item())\n",
    "    \n",
    "    if len(loss_history) % 50 == 0:\n",
    "        recall = eval_recall()\n",
    "        recall_history.append(float(recall))\n",
    "        \n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=[15, 4])\n",
    "        plt.subplot(1, 3, 1);\n",
    "        plt.title('loss, mean = %0.5f' % np.mean(loss_history[-100:])); plt.grid()\n",
    "        plt.plot(loss_history)\n",
    "        \n",
    "        plt.subplot(1, 3, 2);\n",
    "        plt.title('regularizer, mean = %0.5f' % np.mean(reg_history[-100:])); plt.grid()\n",
    "        plt.plot(reg_history)\n",
    "\n",
    "        plt.subplot(1, 3, 3);\n",
    "        probs = torch.sigmoid(emb.edge_adjacency_logits).data.numpy().ravel()\n",
    "        plt.title('P(edge), nonzero rate = %.5f' % (np.sum(probs > 0.5) / total_edges))\n",
    "        plt.grid();\n",
    "        plt.hist(probs)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title('recall')\n",
    "        plt.plot(recall_history)\n",
    "        plt.show()\n",
    "        \n",
    "        if emb.report_model_size()['num_parameters'] / (num_users + num_items) < 8.0: \n",
    "            print(\"Reached target compression rate, exiting\")\n",
    "            break\n",
    "\n",
    "# batch/s rate will increase at 5k and 10k steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ix, pos_items = map(torch.tensor, zip(*data.testRatings))\n",
    "assert torch.all(user_ix == torch.arange(num_users)).item()\n",
    "neg_items = torch.as_tensor(data.testNegatives)\n",
    "pos_and_neg = torch.cat([pos_items[:, None], neg_items], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_pruned = emb.pruned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_indices = []\n",
    "for batch_start in range(0, num_users, batch_size):\n",
    "    print(end='.')\n",
    "    batch = slice(batch_start, batch_start + batch_size)\n",
    "    pred_pos_and_neg = emb_pruned(user_to_vertex(user_ix)[batch], item_to_vertex(pos_and_neg)[batch],\n",
    "                                  deterministic=True)\n",
    "    ordered = pred_pos_and_neg['target_distances'].data.numpy().argsort(-1)\n",
    "    positive_indices.extend(np.array([list(row).index(0) for row in ordered]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(positive_indices) < 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(positive_indices) < 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"params per vertex = %.4f\" % (emb_pruned.report_model_size()['num_parameters'] / (num_users + num_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
