{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook\n",
    "builds a graph-based embedding for a small number of random handwritten digits with multidimensional scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: run this before import to recompile c++ ops\n",
    "```\n",
    "!rm -r ../lib/cpp/temp/\n",
    "!rm -r ../lib/cpp/build/\n",
    "!rm -r ../lib/cpp/_bindings.so\n",
    "!rm -r ../lib/cpp/bindings.py\n",
    "!rm -r ../lib/cpp/lib_wrap.c\n",
    "```\n",
    "\n",
    "\n",
    "##### Get the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from itertools import product, islice, chain\n",
    "import math\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, TruncatedSVD\n",
    "from sklearn.manifold import MDS\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024 # 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(iterable, size=10):\n",
    "    iterator = iter(iterable)\n",
    "    for first in iterator:\n",
    "        yield chain([first], islice(iterator, size - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standard FashionMNIST dataset\n",
    "num_samples = 10000\n",
    "\n",
    "_dim = 0  # assume square images, if not, use _dim1, _dim2\n",
    "X, y = [], []\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()                             \n",
    "    ])\n",
    ")\n",
    "loader = torch.utils.data.DataLoader(train_set, batch_size = num_samples)\n",
    "for batch in loader:\n",
    "    X, y = batch[0], batch[1]\n",
    "    _dim = X.shape[-1]\n",
    "    X = X.reshape(num_samples, _dim**2)\n",
    "    X = X / np.square(X).sum(-1, keepdims=True) ** 0.5\n",
    "    X = X.numpy()\n",
    "# oops took the last batch by mistake, to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./temp.hdf'):\n",
    "    print(\"HDF5 file for pairwise distance for original dataset already exists, skipping this step!')\n",
    "else:\n",
    "    print(\"Generating pairwise distance for original dataset, writing to HDF5 file...\")\n",
    "    _generator = product(X, repeat=2)\n",
    "    num_chunks = 100\n",
    "    chunk_size = math.ceil(num_samples**2 / num_chunks)\n",
    "\n",
    "    h5f = h5py.File('./temp.hdf', 'a')\n",
    "    for _chunk in tqdm(chunks(_generator, chunk_size), total=num_chunks):\n",
    "        distances = np.square([np.subtract(x[0], x[1]) for x in _chunk]).sum(-1)\n",
    "        if \"dataset\" not in h5f:\n",
    "            h5f_dataset = h5f.create_dataset('dataset', data=distances, compression=\"gzip\", chunks=True, maxshape=(None, )) \n",
    "        else:\n",
    "            h5f_dataset.resize((h5f_dataset.shape[0] + distances.shape[0]), axis = 0)\n",
    "            h5f_dataset[-distances.shape[0]:] = distances\n",
    "    h5f.close()\n",
    "\n",
    "distances = []\n",
    "with h5py.File('temp.hdf','r') as infile:\n",
    "    distances = infile['dataset'][:]\n",
    "distances = distances.reshape(num_samples, num_samples)\n",
    "\n",
    "_elapsedTime = (time.time() - _start) / 60\n",
    "print(\"Total time taken: \", _elapsedTime)\n",
    "del _start, _elapsedTime\n",
    "\n",
    "# 10000 samples **2 will take 20mins /w 100 chunks\n",
    "    # hits around 9gb RAM usage, double 'num_chunks' if MemoryError\n",
    "    # 350MB HDF5 file, 400MB RAM\n",
    "    # 3 hr training time?\n",
    "# 60000 samples **2 will take 36 times longer i.e. 12hr\n",
    "    # probably 12.6gb HDF5 file, 14,4gb RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _storage = np.memmap('memmap.np', shape=(num_samples, _dim*_dim), dtype=float32, mode='wb+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build initial graph\n",
    "\n",
    "We initialize prodige with a full graph initialized with distances between nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.task.compression import make_graph_from_vectors\n",
    "emb = make_graph_from_vectors(\n",
    "    X, knn_edges=100, max_length=10, n_jobs=-1, soft=True, directed=False, verbose=True\n",
    ")\n",
    "\n",
    "opt = torch.optim.SparseAdam(emb.parameters(), lr=0.01)\n",
    "\n",
    "loss_history, reg_history = [], []\n",
    "\n",
    "# uncomment to deliberately mess with weights for testing purposes\n",
    "# emb.edge_weight_logits.reset_parameters()\n",
    "# emb.edge_adjacency_logits.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loop\n",
    "\n",
    "Here we minimize the MDS loss function\n",
    "$$L = 1/N \\sum_{i, j} (d_{orig}(x_i, x_j) - d_G(v_i, v_j))^2$$\n",
    "\n",
    "* $d_{orig}(x_i, x_j)$ is the original distance between two vectors in $X$\n",
    "* $d_G(v_i, v_j)$ is the learned graph distance between corresponding vertices in graph $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_i in tqdm(range(len(loss_history), 650)): # 1000\n",
    "    ii = torch.randint(0, len(X), [batch_size])\n",
    "    jj = torch.randint(0, len(X), [batch_size])\n",
    "\n",
    "    pred = emb(ii, jj)\n",
    "    distances_ref = torch.as_tensor(distances[ii, jj], dtype=torch.float32)\n",
    "    \n",
    "    reconstruction_mse = F.mse_loss(pred['target_distances'], distances_ref)\n",
    "    \n",
    "    if len(loss_history) < 325: # 5000\n",
    "        regularizer = emb.compute_l0_prior_penalty(batch_size=4096)\n",
    "    else:\n",
    "        regularizer = emb.compute_hierarchical_prior_penalty(nonzero_rate=0.05, batch_size=4096)\n",
    "\n",
    "    lambd = min(1, len(loss_history) / 5000.) * 10.0\n",
    "    loss = reconstruction_mse - pred['logp_target_paths'].mean() + lambd * regularizer\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_history.append(reconstruction_mse.item())\n",
    "    reg_history.append(regularizer.item())\n",
    "    \n",
    "    if len(loss_history) % 10 == 0: # 50\n",
    "        clear_output(True)\n",
    "        plt.figure(figsize=[15, 4])\n",
    "        plt.subplot(1, 3, 1);\n",
    "        plt.title('reconstruction mse, mean = %0.5f' % np.mean(loss_history[-100:])); plt.grid()\n",
    "        plt.plot(loss_history)\n",
    "        \n",
    "        plt.subplot(1, 3, 2);\n",
    "        plt.title('regularizer, mean = %0.5f' % np.mean(reg_history[-100:])); plt.grid()\n",
    "        plt.plot(reg_history)\n",
    "\n",
    "        plt.subplot(1, 3, 3);\n",
    "        probs = torch.sigmoid(emb.edge_adjacency_logits).data.numpy().flatten()\n",
    "        nnz_rate = np.mean(probs > 0.5)\n",
    "        plt.title('P(edge), nonzero rate = %.5f' % nnz_rate); plt.grid();\n",
    "        plt.hist(probs)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_ours = emb.compute_pairwise_distances()\n",
    "print(\"PRODIGE: %.5f\" % np.mean(np.square(distances - distances_ours)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('./temp_pca.hdf'):\n",
    "    print(\"HDF5 file for pairwise distance for PCA already exists, skipping this step!')\n",
    "else:\n",
    "    print(\"Generating pairwise distance for PCA, writing to HDF5 file...\")\n",
    "\n",
    "    pca = PCA(n_components=4).fit(X)\n",
    "    ### pca = IncrementalPCA(n_components=4, batch_size=batch_size).fit(X)\n",
    "    X_pca = pca.inverse_transform(pca.transform(X))\n",
    "\n",
    "    _generator = product(X_pca, repeat=2)\n",
    "    num_chunks = 100\n",
    "    chunk_size = math.ceil(num_samples**2 / num_chunks)\n",
    "\n",
    "    h5f = h5py.File('./temp_pca.hdf', 'a')\n",
    "    for _chunk in tqdm(chunks(_generator, chunk_size), total=num_chunks):\n",
    "        distances = np.square([np.subtract(x[0], x[1]) for x in _chunk]).sum(-1)\n",
    "        if \"dataset\" not in h5f:\n",
    "            h5f_dataset = h5f.create_dataset('dataset', data=distances, compression=\"gzip\", chunks=True, maxshape=(None, )) \n",
    "        else:\n",
    "            h5f_dataset.resize((h5f_dataset.shape[0] + distances.shape[0]), axis = 0)\n",
    "            h5f_dataset[-distances.shape[0]:] = distances\n",
    "    h5f.close()\n",
    "\n",
    "distances_pca = []\n",
    "with h5py.File('./temp_pca.hdf','r') as infile:\n",
    "    distances_pca = infile['dataset'][:]\n",
    "distances_pca = distances_pca.reshape(num_samples, num_samples)\n",
    "print(\"PCA:\\t %.5f\" % np.mean(np.square(distances - distances_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_start = time.time()\n",
    "\n",
    "mds = MDS(n_components=4, random_state=42, n_jobs=2, dissimilarity='euclidean', verbose=1)  # 2 hrs\n",
    "X_mds = mds.fit_transform(X)\n",
    "distances_mds = np.square(X_mds[None, :, :] - X_mds[:, None, :]).sum(-1) ** 0.5\n",
    "print(\"MDS:\\t %.5f\" % np.mean(np.square(distances - distances_mds)))\n",
    "\n",
    "# svd = TruncatedSVD(n_components=4, algorithm='arpack')  # Very fast\n",
    "# X_svd = svd.fit_transform(X)\n",
    "# distances_svd = np.square(X_svd[None, :, :] - X_svd[:, None, :]).sum(-1) ** 0.5  # Probably causes memory issues\n",
    "# print(\"SVD:\\t %.5f\" % np.mean(np.square(distances - distances_svd)))\n",
    "\n",
    "_elapsedTime = (time.time() - _start) / 60\n",
    "print(\"Total time taken: \", _elapsedTime)\n",
    "del _start, _elapsedTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh import io\n",
    "from bokeh.plotting import figure, output_file, save\n",
    "output_file('mnist_graph.html')\n",
    "emb.default_distance.data[...] = 100\n",
    "p = lib.visualize_embeddings(emb, vertex_labels=y, edge_probability_threshold=0.5, deterministic=True,\n",
    "                         vertex_alpha=0.8, cmap=lambda x: plt.get_cmap('rainbow')(x))\n",
    "save(p, 'mnist_graph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(filename=\"graph.html\")\n",
    "# re-run several times to get different tsne optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
